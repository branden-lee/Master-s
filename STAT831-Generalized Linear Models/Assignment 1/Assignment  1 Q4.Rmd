---
title: "STAT831: Assignment 1"
author: "Branden Lee 20877653"
header-includes: \usepackage{amsmath}
geometry: margin=2cm
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Question 4

(a) Under the log link $\eta = g(\mu)=log(\mu)$,
$$\frac{\partial \eta_i}{\partial\mu_i} = \frac{1}{\mu_i} = e^{-x_i^t\beta}, \quad W_i^{-1} = Var(y_i) \left( \frac{\partial \eta_i}{\partial\mu_i} \right)^2
  = \frac{\mu_i^3}{\lambda} \left( \frac{1}{\mu_i} \right)^2
  = \frac{\mu_i}{\lambda}
  = \frac{e^{x_i^t\beta}}{\lambda}$$
\begin{align*}
  \implies S(\beta)_j & = \sum_{i=1}^n (y_i - \mu_i) W_i \frac{\partial \eta_i}{\partial \mu_i} x_{ij} \\
  & = \sum_{i=1}^n (y_ - e^{x_i^t\beta}) \frac{\lambda}{e^{x_i^t\beta}} \frac{1}{e^{x_i^t\beta}} x_{ij} \\
  & = \sum_{i=1}^n (y_ - e^{x_i^t\beta}) \lambda e^{-2x_i^t\beta} x_{ij} \\
  \mathcal{I}(\beta)_{jk} & = \sum_{i=1}^n x_{ij} W_i x_{ik} \\
  & = \lambda \sum_{i=1}^n x_{ij} e^{-x_i^t\beta} x_{ik}
\end{align*}
 
 \newpage
(b)
```{r, tidy=TRUE}
lambda = 140000
y <- c(92.00, 92.00, 91.25, 85.62, 84.90, 87.88, 87.88, 87.57, 90.25, 88.40, 89.45, 96.38,
       94.62, 91.23)
x <- c(42,43,44,46,48,49,50,51,57,59,60,61,62,63)
Xt <- matrix(c(rep(1, 14), x, x^2), ncol=3)

score <- function(b) {
  s <- c()
  for (j in 1:3) {
    sum <- 0
    for (i in 1:14) {
      sum <- sum + exp(-2 * Xt[i,] %*% b) * (y[i] - exp(Xt[i,] %*% b)) * Xt[i,j]
    }
    s[j] <- lambda * sum
  }
  return(s)
}

irls <- function(b, eps) {
  beta_old <- b
  w <- c()
  for (i in 1:14) {
    w[i] <- exp(-Xt[i,] %*% beta_old)
  }
  W <- lambda * diag(w)
  exp_inf <- t(Xt) %*% W %*% Xt
  beta_new <- beta_old + solve(exp_inf) %*% score(beta_old)
  while ((sum(beta_old - beta_new)^2)^0.5 >= eps) {
    beta_old <- beta_new
    beta_new <- beta_old + solve(exp_inf) %*% score(beta_old)
    
  }
  return(beta_new)
}

print(irls(c(5, -.05, .0005), .0001))
```

Setting $\beta_0 = (5, -.05, .0005)$ with an error of less than .0001 using the euclidean norm, we get 
$$\hat{\beta} = (`r irls(c(5, -.05, .0005), .0001)`)$$.



